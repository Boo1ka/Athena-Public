---
created: 2025-12-31
last_updated: 2026-01-30
graphrag_extracted: true
---

---id: "244"
title: "Offensive Reframing (Incentive Physics)"
type: "Strategy"
tags: ["sales", "negotiation", "game_theory", "risk", "reframing", "signaling_theory"]
created: "2025-12-31"
related: ["112", "197", "003"]
description: "A method to counter trust-based objections by optimizing the 'defect' strategy to absurdity, proving non-defect via revealed preference and constraints."
last_updated: 2026-01-05
---

# Protocol 244: Offensive Reframing (Incentive Physics)

> **Core Principle**: Don't defend your integrity (words). Prove your incentive physics (constraints). Integrity is a story; incentives are physics.

## 0. Prerequisites
>
> **Warning**: You must have high domain competence to use this.
> If you try to explain "How a scammer works" but get the details wrong, you prove you are neither honest nor competent.
> **You must know the Dark Arts to renounce them.**

## 1. The Dynamic

When a counterparty asks a "Trust Question" (e.g., "How do I know you won't steal my money?"), they are asking for **reassurance**.
Most people answer with **defense**: "I promise I am honest." (Weak. Words are cheap).
The High-Agency answer is **offense**: "If I were going to steal, I wouldn't do it *this badly*." (Strong. Proof via Competence).

> [!WARNING]
> **The Sociopath Trap**: This strategy proves you *know* how to hurt them. If delivered without warmth, it signals "Calculated Predator."
> **Fix**: You must frame the "Dark Strategy" not just as immoral, but as **strategically inferior**.
>
> * *Bad*: "I could steal your money, but I won't." (Trust me).
> * *Good*: "Stealing your money is short-term thinking. I am playing a long-term reputation game. Churning this account kills the golden goose."

## 2. The Mechanism (Reductio + Constraints)

You validate their fear by taking it to its logical extreme, showing your current behavior is incompatible with a bad actor's incentives, and then **locking it in with a constraint**.

### The Formula

1. **Accept the Frame**: "That is a valid fear. Let's explore it."
2. **Optimize the Defect**: "If I *were* going to [Screw You], I wouldn't do [Current Action]. I would do [Optimal Scam]."
3. **Contrast**: "But I am doing [Current Action]. So either I am the world's worst scammer, or I am actually playing the Long Game."
4. **The Constraint (Critical)**: "But you shouldn't trust my math either. Let's set up [Constraint] so I *can't* do that."

## 3. Canonical Case: The Gambler's Hypothetical

**Objection**: "How do I know you won't gamble with my $10K trading account?"

**Defensive Answer (Weak)**: "Trust me, I have a plan."

**Offensive Reframing (Strong)**:
> "Fair concern. Honestly, if I *was* trying to churn you, here is exactly what I would do:
>
> 1. I wouldn't ask for just $10K with 1:1 leverage. I'd ask for $50K and max leverage.
> 2. I wouldn't trade these slow setups. I'd churn your account 500 times a day to farm affiliate rebates.
>
> That is how a *real* bad actor extracts value. I'm proposing the opposite structure.
>
> **Constraint**: But words are cheap. Let's set the account to **Read-Only** access for me, with a hard equity stop-loss at 5% managed by the broker. That way, I literally *cannot* blow the account."

## 4. Why This Works

1. **Costly Signaling**: You signal competence by revealing you know the "Dark Game," which implies you've chosen against it.
2. **Incentive Alignment**: You shift from "Morality" (Subjective) to "Physics" (Objective).
3. **False Dichotomy Breaker**: Step 4 (The Constraint) prevents the "Long Con" counter-argument. You aren't just "not doing it yet"; you are *unable* to do it.

## 5. Applications

| Scenario | Fear | Offensive Reframe + Constraint |
| :--- | :--- | :--- |
| **Consulting** | "Will you drag this out?" | "If I wanted to milk this, I wouldn't give you a Flat Fee. I'd ask for 'Time & Materials' with vague scope. That is how consultants buy Ferraris—by shifting risk to the client. By giving you a Fixed Price, I accept the risk. If I drag it out, I lose money."<br>**Constraint**: Fixed Price + Defined Deliverables. |
| **Dating** | "Are you just using me?" | "If I was just looking for a hookup, I would have bailed three hours ago when the conversation got heavy. Players look for the easy yes (Path of Least Resistance). I’m still here because I’m actually interested in *you*."<br>**Constraint**: Consistent Investment (Time/Action). |
| **Hiring** | "Will you leave in 3 mo?" | "If I wanted a quick hop, I wouldn't be grilling you this hard on the 5-year equity vesting schedule."<br>**Constraint**: 1-Year Cliff on Equity. |

## 6. Guardrails

### When to Use

* **Generic Trust Anxiety**: When the person is rational but fearful.
* **Established Status**: You must have established competence first.

### When NOT to Use

* **Regulations**: In finance/healthcare, "joking" about fraud can be a compliance violation.
* **Trauma**: Do not use Reductio logic on deep emotional trauma.
* **Process Proof**: If they need a SOC2 report, give them a SOC2 report.

## 7. Related Protocols

* **[Protocol 112 (Form-Substance)](file:///Users/[AUTHOR]/Desktop/Project Athena/.agent/skills/protocols/pattern-detection/112-form-substance-gap.md)**: Distinguishing optics from reality.
* **[Protocol 197 (Consigliere)](file:///Users/[AUTHOR]/Desktop/Project Athena/.agent/skills/protocols/decision/329-consiglieri-protocol.md)**: Seeing the board from the "Dark" perspective.
